{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from CSIP.utils import unload_data\n",
    "from CSIP.dataset import GraphDataset, GraphLoader\n",
    "from CSIP.model.GIN import GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (layers): ModuleList(\n",
       "    (0): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=45, out_features=64, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): GraphNorm(\n",
       "          (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (4): GraphNorm(\n",
       "          (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (final_linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (1-2): 2 x MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): GraphNorm(\n",
       "          (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (4): GraphNorm(\n",
       "          (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (final_linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (to_labels): Linear(in_features=64, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_img = GNN(labels = 8, input_dim = 256, num_layers = 3, hidden_dim = 64, \n",
    "                num_mlps = 2, pad = 80, graph_dim = 64, use_lstm = False)\n",
    "model_img.eval()\n",
    "\n",
    "model_mol = GNN(labels = 8, input_dim = 45, num_layers = 3, hidden_dim = 64, \n",
    "                num_mlps = 2, pad = 80, graph_dim = 64, use_lstm = False)\n",
    "model_mol.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graphs...\n",
      "Loading nodes...\n",
      "Loading ground truth label...\n"
     ]
    }
   ],
   "source": [
    "load_dir = 'D:/Cell painting/10000' ## path to your data\n",
    "\n",
    "graph, nodes, labels = unload_data(load_dir, load_label=1)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing SMILES...: 100%|██████████| 10000/10000 [00:15<00:00, 644.75it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = GraphDataset(features = nodes, graphs = graph, labels = labels,  \n",
    "                             pad = 80, size = 256, norm = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = 'CSIP/parameters/checkpoint.pth' ## path to model checkpoint\n",
    "\n",
    "ckpt = torch.load(ckpt)\n",
    "start_iter = ckpt['iter']\n",
    "model_img.load_state_dict(ckpt['model_img_state'])\n",
    "model_mol.load_state_dict(ckpt['model_mol_state'])\n",
    "\n",
    "logging.debug(\"All keys are matched successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, mols = [], []\n",
    "for i in range(len(dataset)):\n",
    "    features, graphs, (labels_graphs, labels_features), _ = dataset[i]\n",
    "    features = torch.unsqueeze(features, 0)\n",
    "    labels_features = torch.unsqueeze(labels_features, 0)\n",
    "\n",
    "    image_features = model_img([graphs], features)\n",
    "    mol_features = model_mol([labels_graphs], labels_features)\n",
    "\n",
    "    imgs.append(F.normalize(image_features))\n",
    "    mols.append(F.normalize(mol_features))\n",
    "    \n",
    "imgs = torch.cat(imgs)\n",
    "mols = torch.cat(mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_m = torch.einsum('id,jd->ij', imgs, mols)\n",
    "m_m = torch.einsum('id,jd->ij', mols, mols)\n",
    "repeats_m = (m_m >= 0.99999).to(torch.int32)\n",
    "m_idxs = torch.argmax(repeats_m, 1, keepdim = True)\n",
    "mol_candidates = mols[torch.unique(m_idxs)]\n",
    "\n",
    "ground_truth = torch.zeros(imgs.size(0), mols.size(0))\n",
    "for i in range(len(m_idxs)): \n",
    "    ground_truth[i, m_idxs[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 10 ### top-x accuracy\n",
    "match = torch.topk(i_m, k = topk, dim = -1)[1].T\n",
    "correct_i2m = torch.sum(torch.max(ground_truth[torch.arange(imgs.size(0)), match], dim = 0)[0]).item() / imgs.size(0)\n",
    "logging.debug(f\"Top_{topk} retrieval accuracy: {correct_i2m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top_10 retrieval accuracy: 0.0033\n"
     ]
    }
   ],
   "source": [
    "print(f\"Top_{topk} retrieval accuracy: {correct_i2m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004366812227074236"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / len(mol_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
